# ✒️فصل سوم. ذخیره و بازیابی
هدف نوشتن در پایگاه داده و سپس بازیابی اطلاعات است.

## Data structures for Databases
یک مثال ساده از یک بانک اطلاعاتی زده:
- ذخیره: اضافه به انتهای یک فایل - داده جدید جایگزین نمی‌شود بلکه فقط اضافه می‌شود.
- ‫بازیابی: استفاده از دستور grep برای کلید

کارایی نوشتن بسیار بالاست. در پایگاه‌های داده چیزی به نام
log
برای نوشتن استفاده می‌شود که به همین صورت کار می‌کند.

اما کارایی خواندن وقتی داده زیاد باشد بسیار پایین است.
برای بهبود زمان خواندن، از ایندکسینگ استفاده می‌کنیم.

ایندکس داده‌ای اضافه و به دست آمده از داده‌ی اصلی است.

ایندکس‌ها زمان نوشتن را بیشتر می‌کنند، و به صورت پیش‌فرض اعمال نمی‌شوند. توسعه‌دهنده‌ی سیستم باید فیلد(هایی) که ایندکس لازم دارند معرفی کند.

### Hash indexes
از ساختار
hash-map
که در زبان‌های برنامه‌نویسی پشتیبانی می‌شود استفاده می‌کند.
یک
hash-map
در حافظه‌ی اصلی برنامه کلید‌ها را نگه می‌دارد و هر کلید مکان رکورد در فایل را نشان می‌دهد.

این روشی است که
Bitcask
موتور ذخیره‌سازی پیش‌فرض
Riak
استفاده می‌کند.
در این سیستم، موتور باید قادر باشد تمام کلیدها را همزمان در حافظه اصلی نگه دارد.
از آن جا که عملیات نوشتن بدون جایگزینی است (فقط به انتهای فایل اضافه می‌کند)، به صورت دوره‌ای فایل‌ها را (داده‌ها در فایل‌های با سایز مشخص می‌نویسد و با رسیدن به سایز فایل دیگری آغاز می‌کند) از نو می‌نویسد (و اگر بتواند ترکیب می‌کند) و داده‌های تکراری خود به خود حذف می‌شوند.

چالش‌های پیاده‌سازی:
- فرمت فایل: باینری با یک رشته که طولش در ابتدا آمده
- حذف رکورد: نوشتن یک رکورد جدید tombstone
- بازیابی از کرش: خواندن دوباره‌ی همه‌ی فایل‌ها. اما در این پیاده‌سازی هش‌مپ هر فایل همراهش نوشته می‌شود که کار خواندن را ساده‌تر کند.
- رکوردهای نصفه نوشته شده:  چک‌سام هر فایل وجود دارد و با در نظر گرفتن آن می‌شود بعضی رکوردها را در نظر نگرفت
- کنترل اجرای همزمان: فقط یک ترد نویسنده وجود دارد

محدودیت‌های این نوع ایندکس:
- محدودیت حافظه: به رم محدود است
- پرس و جوهای بازه‌ای را پاسخگو نیست - range queries

### SSTables and LSM-Trees
SSTable: Sorted String Table

هر سگمنت را بر اساس کلید مرتب نگه‌می‌دارد که عملیات مرج را ساده می‌کند.

> ``📝`` در کتاب «نوشتن در سگمنت» را در انتها توضیح داده که برای من گیج‌کننده بود. توضیح را در ابتدا می‌آورم:

نوشتن در سگمنت:
- به جای
hash-map
در حافظه یک درخت بالانس شده مانند
red-black یا AVL
نگه می‌دارد: memtable
- وقتی حجم
memtable
به حد مشخصی رسید، آن را در یک فایل
SSTable
می‌نویسد. در حین نوشتن، نوشتن‌های جدید در یک
memtable
جدید ذخیره می‌شوند
- برای خواندن، ابتدا حافظه جستجو می‌شود، سپس اخیرترین سگمنت، بعد قبلی آن و به همین ترتیب
- گاه به گاه، پروسه‌ی مرج و فشرده‌سازی صورت می‌گیرد که سگمنت‌ها را ترکیب می‌کند و رکوردهای پاک شده را دور می‌ریزد
- برای اجتناب از گم شدن
memtable
در زمان کرش، رکوردها را در یک فایل لاگِ بدون ترتیب نوشته و هر زمان
memtable
در فایل نوشته شد فایل لاگ را پاک می‌کند.

مزایای
SSTable
نسبت به سگمنت‌هایی که از ایندکس
hash
استفاده می‌کنند:
- مرج آسان‌تر است
- برای یافتن رکوردی در فایل، نیاز به نگه‌داری همه‌ی کلید‌ها نیست. آدرس رکوردی نزدیک آن کافی‌ست که فایل را پیدا کند.
- در خواندن نیاز است چند رکورد نزدیک پیمایش شوند، پس می‌توان این رکوردها را در یک بلوک قرار داد و قبل از نوشتن رو دیسک فشرده کرد. این فشرده‌سازی در فضای دیسک و حجمِ نوشته/خوانده‌شده صرفه‌جویی می‌کند.

#### LSM-tree out of SSTables
LSM-Tree: log-structured merge-tree

الگوریتم‌های ذکر شده در
LevelDB و RocksDB
استفاده می‌شوند که کتاب‌خانه‌های موتورهای ذخیره‌ی 
key-value
هستند.

مثلا
LevelDB
را در
Riak
می‌توان به جای
Bitcask
استفاده کرد.

موتورهای ذخیره‌سازی مشابه در
Cassandra و HBase
استفاده می‌شوند.

این‌ها همه از مقاله‌ی
Bigtable
گوگل الهام گرفته‌اند که واژه‌های
SSTable و memtable
را معرفی کرد.

چنین ساختاری در
Lucene
که موتور ایندکسینگ
Elasticsearch و Solr
است استفاده می‌شود.

> **Note**: Lucene is _full-text search_ indexing engine.

#### Performance optimization

- با توجه به زمان زیادی که برای اعلام عدم موجودی یک کلید نیاز است، از ساختارهایی چون
[Bloom filter](https://en.wikipedia.org/wiki/Bloom_filter)
برای اعلام عدم وجود کلید استفاده می‌شود.
- استراتژی‌های مختلف برای فشرده‌سازی و مرج
SSTableها
به کار گرفته می‌شود. 

در کل
write throughput
در
LSM-Treeها
بسیار بالاست.

### B-Trees
رایج‌ترین ساختار برای ایندکس‌گذاری
B-Trees
هستند.

پایگاه داده را به بلوک‌های با طول ثابت (به صورت سنتی ۴ کیلوبایتی) می‌شکنند.
هر با یک صفحه را می‌نویسند یا می‌خوانند.
هر صفحه آدرسی برای دستیابی روی دیسک دارد و می‌تواند آدرس صفحات دیگری را نگه دارد.
یک صفحه‌ی
root
درخت را آغاز می‌کند و برگ‌های درخت بازه‌ای از کلیدها را ذخیره می‌کنند.
این بازه‌ها اشاره‌گرهایی به صفحه‌های دیگر (برگ) دارند که بتوان بازه را در آن‌ها نیز دنبال کرد.

به
branching factor
هم اشاره کرده.
معمولا چیزی حدود چندصد است.

این نوع درخت با شکستن صفحه‌ها رشد می‌کنند
و الگوریتم بالانس درخت را حفظ می‌کند.

مثال: یک درخت چهارسطحی با صفحات ۴ کیلوبایتی و فاکتور شاخه‌شاخه شدن ۵۰۰، می‌تواند تا ۲۵۰ ترابایت ذخیره کند.

#### Making B-trees reliable
اضافه کردن به یک صفحه یعنی تغییر آن در محلی که هست. این با ساختار
SSTable
متفاوت است که همه‌چیز فقط اضافه می‌شد.

اگر صفحه به خاطر افزودن یک کلید از سایز حد بیشتر شود و شکسته شود، اشاره‌گرهای والدین هم باید تصحیح شود.
در این حین اگر کرش اتفاق بیفتد داده‌ها ناسازگار خواهند بود.

برای حل، از
WAL (write-ahead log or redo log)
استفاده می‌شود.
هر چیزی قبل از نوشته شدن روی درخت، در این لاگ نوشته می‌شود و در بازیابی خطا، دوباره این تغییرات روی درخت اعمال می‌شود.

مشکل دیگر همزمانی در تغییر داده‌های درخت است، که برای حل با 
latches
(قفل‌های سبک)
از ساختار درخت محافظت می‌شود.

> ``📝`` در مورد بهینه‌سازی این نوع درخت هم پنج مورد اشاره کرده که خلاصه نکردم.

### B-Trees vs LSM-Trees
- سرعت نوشتن در
LSM-Trees
و سرعت خواندن از
B-Trees
بیشتر از دیگری است.

در
log-structured indexes
(همان درخت‌های LSM)
یک عملیات نوشتن در واقع شامل چند بار نوشتن در دیسک (در طول عمر پایگاه داده) است که
write amplification
خوانده می‌شود.
این باعث پایین آمدن
write throughput
می‌شود چون پهنای باند دیسک محدود است.
این قضیه در
SSDها
مشکل بیشتری نشان می‌دهد چون ظرفیت نوشتنشان (تعداد نوشتن)
محدود است.

یک مزیتِ داشتنِ یک نسخه‌ی واحد از هر ایندکس در
LSM-Trees
امکان‌پذیر شدن پشتیبانی قوی از تراکنش است
(strong transactional semantics).
در بسیاری از پایگاه‌های داده‌ی رابطه‌ای تفکیک تراکنش
(transaction isolation)
با استفاده از قفل
(lock)
روی بازه‌ای از کلید‌ها پیاده‌سازی می‌شود و در یک اندیس
B-Tree
این قفل‌ها می‌توانند مستقیما به درخت متصل باشند.

### Other indexing structures
کلیدهای
secondary
می‌توانند به سادگی با یک ایندکس
کلید-مقدار
(key-value)
ساخته شوند. تفاوت اصلی این پیاده‌سازی با کلیدهای اصلی
(primary)
یکتا نبودن کلیدهاست.

برای پیاده‌سازی،
- یا مقادیر متصل به هر کلید لیست در نظر گرفته می‌شوند
(و مثلا شماره سطرهای رکوردها با این کلید در این لیست قرار می‌گیرند)، یا
- با اضافه کردن شماره سطر به کلید، یک کلید یکتا ساخته می‌شود

#### ذخیره‌سازی مقادیر در ایندکس
دو روش وجود دارد:
- تمام رکورد در هر ایندکس ذخیره شود
(clustered index)
- رکورد در یک فایل بدون ترتیب
(heap file)
ذخیره می‌شود و شماره سطر در ایندکس ذخیره می‌شود
(non-clustered index)

در روش دوم، آپدیت محتوای رکورد ایندکس را تغییر نمی‌دهد مشروط بر این که اندازه‌ی رکورد جدید بزرگ‌تر نشده باشد.
در صورت بزرگ‌تر شدن، یا
- جای رکورد عوض شده و ایندکس‌ها به روز می‌شوند، یا
- یک اشاره‌گر به محل جدید رکورد در فایل قرار داده می‌شود و رسیدن به رکورد نیازمند یک پرش اضافی
(extra hop)
است.

در جدول‌های 
InnoDB
از
MySQL
از
clustered index
استفاده می‌شود و ایندکس‌های
secondary
به مکان کلید اصلی اشاره می‌کنند.

در
SQL Server
هر جدول می‌تواند یک
clustered index
داشته باشد.

#### ایندکس‌های چند ستونه
یک روش معمول
concatenated index
است که همه‌ی مقادیر دخیل را به هم می‌چسباند. مانند نام و فامیل در دفترچه تلفن.

این روش برای جستجوی بازه‌ای مناسب نیست.
چیزی که برای مثال در مکان‌یابی لازم است:

```sql
SELECT * FROM restaurants WHERE
    latitude > 51.4946 AND latitude < 51.5079 AND
    longitude > -0.1162 AND longitude < -0.1004
```
این پرس و جو  فقط یک سطح از ایندکس‌های ذکر شده را استفاده کرده و برای فیلد بعدی مجبور به جستجوی خطی است.

این فقط به مکان‌یابی منحصر نیست و جستجوهایی مثل یافتن رنگ مشابه (با داشتن قرمز، سبز و آبی)
یا میزان بارش بیشتر از ۳ میلی‌متر در روزهایی که دمای هوا در بازه‌ای مشخص بود مثال‌های دیگری از آن هستند.

یک روش حل، استفاده از
space-filling curve
برای تبدیل موقعیت مکانی به یک عدد و سپس استفاده از ایندکس‌های معمول است.

روش دیگر، استفاده از
R-Trees
است.
در کتاب راجع به ساختار آن توضیح نداده.
[R-Trees (youtube)](https://youtu.be/S7E-GhQLNnM?t=512).

#### ایندکس‌های «متن کامل» و ایندکس‌های فازی
متن کامل: full-text

جستجوی رشته‌های «شبیه» (مثلا کلماتی که به درستی تایپ نشده‌اند) تکنیک‌های متفاوتی لازم دارد.

در
Lucene،
ساختاری شبیه به
SSTable
استفاده می‌شود که یک ایندکس کوچک در حافظه‌ی اصلی به پرس و جوها می‌گوید باید کدام آفست در فایل مرتب را برای کلید چک کنند.

در
LevelDB
این ایندکس یک مجموعه‌ی اسپارس از کلید است، اما
Lucene
یک ماشین حالت نامتناهی
(finite state automaton)
روی کاراکترهای کلید دارد.
این اتوماتا می‌تواند به
[Levenshtein automaton](https://julesjacobs.com/2015/06/17/disqus-levenshtein-simple-and-fast.html)
تبدیل شود که جستجوهای کارا روی کلمات در هر فاصله‌ی ویرایشی
(edit distance)
می‌دهد.

#### ذخیره‌ی همه چیز در حافظه اصلی
چند مثال از این نوع پایگاه داده زده.
این‌ها از دیسک به صورت
append-only
برای
durability
و بک‌آپ استفاده می‌کنند.

مثال‌ها:
Memcached, VoltDB, Oracle TimesTen, MemSQL, Redis

سرعت این پایگاه‌های داده به خاطر استفاده از رم نیست،
چون سیستم عامل حتی برای پایگاه‌های داده‌ی روی دیسک نیز اگر رم کافی در دسترس باشد دیسک را روی رم
cache
می‌کند،
بلکه به خاطر صرفه‌جویی در سربار زمانیِ تبدیل داده‌های حافظه به فرمتِ قابل نوشتن روی دیسک است.

مزیت دیگر:
پیاده‌سازی ساختارهایی که روی دیسک سخت هستند.
مثلا
Redis،
صف‌های اولویت و ست
(set)
را پیاده‌سازی کرده.

این نوع پایگاه داده، حتی می‌تواند با رویکردی که
anti-caching
خوانده می‌شود فضایی بیشتر از حافظه اصلی را نیز پوشش دهد.
در این حالت مدیریت خواندن و نوشتن رکوردهای مورد دستیابی و قدیمی روی دیسک را خود پایگاه انجام می‌دهد.

## Transaction processing vs Analytics
OLTP: _Online Transaction Processing_

OLAP: _Online Analytical Processing_

الگوی دسترسی به داده در این دو پایگاه داده نوع متفاوت است.

بر خلاف پردازش تراکنشی که معمولا به یک رکورد دست می‌زند، یک پرس و جو در پردازش آنالیتیک باید روی رکوردهای زیادی محاسبات تجمعی انجام دهد
(مانند جمع، معدل، تعداد و از این دست)

برای جلوگیری از قفل شدن تمام سطرهای یک جدول و همچنین دستیابی به کارایی بیشتر پرس و جوهای آنالیتیک،
گاهی برای چنین پرس و جوهایی یک پایگاه داده‌ی مجزا در نظر گرفته می‌شود که
data warehouse
نامیده می‌شود.

### Data warehousing
داده‌ها در
data warehouse
به صورت موازی با داده‌های بانک(های) اصلی (با فرمت معمولا متفاوت و البته به صورت فقط-خواندنی) ذخیره می‌شوند و پرس و جوهای متفاوتی نیز روی آن‌ها انجام می‌شود.


در
Microsoft SQL Server و SAP HANA
هر دو مدل پایگاه داده در یک محصول و با یک واسط
SQL
در دسترس هستند اما در پس‌زمینه هر کدام دو موتور و محل‌های ذخیره‌سازی مجزا دارند.

### Stars, Snowflakes
فرمت نگه‌داری داده‌ها در
data warehouse
معمولا به صورت رابطه‌ای (زبان
SQL
عموما برای این کاربرد مناسب است) و به صورت ستاره‌ای (یا
snowflake
بلور برفی) است.
به این صورت که داده‌های مورد بررسی در مرکز ستاره قرار می‌گیرد (مثلا داده‌های خرید کاربران) و داده‌های مرتبط با آن با کلیدهای خارجی به آن متصل می‌شود.

## Column-oriented structures
- معمولا هر پرس و جو فقط چند ستون محدود را پوشش می‌دهد.
- در این مدل هر ستون در یک فایل مجزا ذخیره می‌شود.

*نکته* این با مفهوم
column families
در
Cassandra و HBase
متفاوت است.

### Column compression
- ستون‌ها اسپارس هستند و به خوبی فشرده می‌شوند.
- موتور بانک، یک ستون فشرده شده را که به راحتی در
L1 cache
جا می‌شود برداشته و یک حلقه‌ی
tight
(بدون فراخوانی تابع - برای این که نیاز به مراجعه به رم نباشد)
روی آن می‌زند.

### Sort order
جدای از سایر توضیحات داده‌شده، ذکر شده که در
C-Store
داده‌ها با چند حالت مرتب شده در مکان‌های مختلف ذخیره می‌شوند.
### Writing
-

### Aggregation
هر
data warehouse
لزوما
column store
نیست.
به صورت سنتی، دیتابیس‌های
row-oriented
هم برای این کار استفاده می‌شده‌اند.

از دیگر جنبه‌های
data warehouses
می‌توان
materialized view
را نام برد که نتیجه‌ی برخی از
aggregationها
را کش می‌کند.

برای مثال در
MySQL
(در کتاب نیست)

```sql
CREATE TABLE sales_summary 
AS 
SELECT product_id, SUM(quantity) as total_sales 
FROM sales 
GROUP BY product_id;
```
هر چند این فقط برای داده‌های داده شده کار می‌کند و اگر پرس و جو نیاز به داده‌ی کش نشده داشته باشد ناچار به استفاده از روال معمول است.
[back](README.md)